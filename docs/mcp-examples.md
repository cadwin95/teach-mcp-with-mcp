---
layout: default
title: MCP ì˜ˆì œ ì½”ë“œ
---

# MCP ì˜ˆì œ ì½”ë“œ

ì‹¤ì œ Python ê¸°ë°˜ MCP ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ ì˜ˆì‹œì…ë‹ˆë‹¤.

---

## 1. MCP ì„œë²„ ê°„ë‹¨ ì˜ˆì œ

```python
from mcp.server.stdio import StdioServer

class EchoServer(StdioServer):
    def handle_request(self, request):
        # ìš”ì²­ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‘ë‹µ
        return {"output": f"Echo: {request.get('input')}"}

if __name__ == "__main__":
    EchoServer().run()
```

---

## 2. MCP í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ

```python
from mcp.client.stdio import stdio_client

# MCP ì„œë²„(EchoServer)ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
with stdio_client("python3 echo_server.py") as client:
    response = client.send({"input": "Hello MCP"})
    print(response["output"])  # Echo: Hello MCP
```

---

## 3. ì™¸ë¶€ ëª¨ë¸(LiteLLM/OpenAI) ì—°ë™ ì˜ˆì‹œ

```python
import litellm

def call_openai(prompt):
    completion = litellm.completion(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return completion['choices'][0]['message']['content']

# MCPì˜ Toolë¡œ ë“±ë¡ ê°€ëŠ¥
```

---

## 4. ì‹¤ì „ í™œìš© íë¦„

1. MCP ì„œë²„ë¥¼ êµ¬í˜„/ì‹¤í–‰
2. í´ë¼ì´ì–¸íŠ¸ì—ì„œ stdio/socket/HTTP ë“±ìœ¼ë¡œ ìš”ì²­
3. ì„œë²„ê°€ ì ì ˆí•œ LLM/íˆ´/DB/APIë¡œ ë¼ìš°íŒ…/ì‹¤í–‰
4. ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ

---

## 5. ë” ì•Œì•„ë³´ê¸°

- [ê³µì‹ ì˜ˆì œ](https://modelcontextprotocol.io/examples)
- [OpenAI Agents SDK MCP ì˜ˆì œ](https://openai.github.io/openai-agents-python/mcp/)

---

[ğŸ”™ ê°œë… ì„¤ëª…ìœ¼ë¡œ](mcp-concept.md)	|â€ƒ[ë©”ì¸ìœ¼ë¡œ](index.md)
